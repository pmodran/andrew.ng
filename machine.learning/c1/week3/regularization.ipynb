{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "\n",
    "import matplotlib.pyplot as plt \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid (x):\n",
    "    g = 1.0/(1.0+np.exp(-x))  # remember function exp() from numpy !!\n",
    "\n",
    "    return g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cost_function (X,y,w,b, lambda_ = 1):\n",
    "    cost  = 0.0\n",
    "    reg_cost = 0.0\n",
    "    m,n = X.shape\n",
    "    for i in range(m):\n",
    "        fwb = np.dot(X[i], w) + b\n",
    "        loss = (fwb - y[i]) ** 2\n",
    "        cost = cost + loss\n",
    "    cost = cost/ ( 2 * m )  # don't forget the paranthesis\n",
    "\n",
    "    for j in range(n):\n",
    "        reg_cost = reg_cost + ( w[j] ** 2)\n",
    "    reg_cost = (reg_cost * lambda_) / (2 * m) \n",
    "    total_cost  =  cost + reg_cost \n",
    "    return total_cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4.17022005e-01 7.20324493e-01 1.14374817e-04 3.02332573e-01\n",
      "  1.46755891e-01 9.23385948e-02]\n",
      " [1.86260211e-01 3.45560727e-01 3.96767474e-01 5.38816734e-01\n",
      "  4.19194514e-01 6.85219500e-01]\n",
      " [2.04452250e-01 8.78117436e-01 2.73875932e-02 6.70467510e-01\n",
      "  4.17304802e-01 5.58689828e-01]\n",
      " [1.40386939e-01 1.98101489e-01 8.00744569e-01 9.68261576e-01\n",
      "  3.13424178e-01 6.92322616e-01]\n",
      " [8.76389152e-01 8.94606664e-01 8.50442114e-02 3.90547832e-02\n",
      "  1.69830420e-01 8.78142503e-01]]\n",
      "[-0.40165317 -0.07889237  0.45788953  0.03316528  0.19187711 -0.18448437]\n",
      "Regularized cost: 0.07917239320214275\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(1) # we set this so we have the same generated numbers each time we run the code \n",
    "X_1 = np.random.rand(5,6)\n",
    "y_1 = np.array([0,1,0,1,0])\n",
    "w_1 = np.random.rand(X_1.shape[1]).reshape(-1,)-0.5\n",
    "b_1 = 0.5\n",
    "lambda_1 = 0.7\n",
    "print(X_1) \n",
    "print(w_1)\n",
    "\n",
    "cost_1 = cost_function(X_1,y_1,w_1,b_1,lambda_1)\n",
    "\n",
    "print(f'Regularized cost: {cost_1}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logistic_cost (X,y,w,b, lambda_ = 1):\n",
    "    m,n = X.shape\n",
    "    cost = 0.0\n",
    "    reg_cost = 0.0\n",
    "    for i in range (m):\n",
    "        z = np.dot(X[i],w) + b\n",
    "        fwb = sigmoid(z)\n",
    "        loss = -y[i] * np.log(fwb) - (1 - y[i] * np.log(1 - fwb))    \n",
    "#        loss = (fwb - y[i])**2    # this is the cost function for linear regression, retard!!!!\n",
    "        cost = cost + loss\n",
    "        print(f'cost bad{cost}')\n",
    "    cost = cost / m\n",
    "\n",
    "\n",
    "    for j in range(n):\n",
    "        reg_cost = reg_cost + (w[j] ** 2)\n",
    "    reg_cost = (reg_cost * lambda_) / (2 ** m)  # remember you divide by 2m again \n",
    "    total_cost = reg_cost +  cost\n",
    "    return total_cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_cost_logistic_reg(X, y, w, b, lambda_ = 1):\n",
    "\n",
    "    m,n  = X.shape\n",
    "    cost = 0.\n",
    "    for i in range(m):\n",
    "        z_i = np.dot(X[i], w) + b                                      #(n,)(n,)=scalar, see np.dot\n",
    "        f_wb_i = sigmoid(z_i)                                          #scalar\n",
    "        cost +=  -y[i]*np.log(f_wb_i) - (1-y[i])*np.log(1-f_wb_i)  \n",
    "        print(f'cost_good{cost}')    #scalar\n",
    "             \n",
    "    cost = cost/m                                                      #scalar\n",
    "\n",
    "    reg_cost = 0\n",
    "    for j in range(n):\n",
    "        reg_cost += (w[j]**2)                                          #scalar\n",
    "    reg_cost = (lambda_/(2*m)) * reg_cost                              #scalar\n",
    "    \n",
    "    total_cost = cost + reg_cost                                       #scalar\n",
    "    return total_cost                                                  #scalar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cost bad-1.0\n",
      "cost bad-2.902434686219554\n",
      "cost bad-3.902434686219554\n",
      "cost bad-5.735742908608744\n",
      "cost bad-6.735742908608744\n",
      "cost_good1.188841623089912\n",
      "cost_good1.5292923594224475\n",
      "cost_good2.570362670042879\n",
      "cost_good2.9312550931710586\n",
      "cost_good4.030021299062049\n",
      "cost_good0.8525624916563554\n",
      "cost_good1.3075089525133248\n",
      "cost_good2.196994889439644\n",
      "cost_good2.5809344239361383\n",
      "cost_good3.2682174003938935\n",
      "Regularized cost for logistic regression:-1.3356343618073667\n",
      "Regularized cost (Corrrected)0.8428497635384328\n",
      "Regularized cost (Even more Corrrected) 0.6850849138741673\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(1)\n",
    "\n",
    "X_tmp = np.random.rand(5,6)\n",
    "y_tmp = np.array([0,1,0,1,0])\n",
    "w_tmp = np.random.rand(X_tmp.shape[1]).reshape(-1,)-0.5\n",
    "b_tmp = 0.5\n",
    "lambda_tmp = 0.7\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "X_2 = np.random.rand(5,6)\n",
    "y_2 = np.array([0,1,0,1,0])\n",
    "w_2 = np.random.rand(X_2.shape[1]).reshape(-1,)-0.5\n",
    "b_2 = 0.5\n",
    "lambda_2 =  0.7\n",
    "cost_2 = logistic_cost(X_2,y_2,w_2,b_2,lambda_2)\n",
    "cost_3 = compute_cost_logistic_reg(X_2,y_2,w_2,b_2,lambda_2)\n",
    "cost_4 = compute_cost_logistic_reg(X_tmp, y_tmp, w_tmp, b_tmp, lambda_tmp)\n",
    "\n",
    "\n",
    "print(f\"Regularized cost for logistic regression:{cost_2}\")\n",
    "print(f\"Regularized cost (Corrrected){cost_3}\")\n",
    "print(f\"Regularized cost (Even more Corrrected) {cost_4}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's compute the gradient with REGULARIZATION\n",
    "\n",
    "def compute_gradient_with_regularization(X,y,w,b,lambda_):\n",
    "    m,n = X.shape\n",
    "    dw = np.zeros((n,))\n",
    "    db = 0.0\n",
    "    for i in range(m):\n",
    "        err = (np.dot(X[i],w) + b) - y[i]\n",
    "        for j in range(n):\n",
    "            dw[j] = dw[j]  + ( err * X[i][j] )\n",
    "        db = db + err\n",
    "    dw = dw / m\n",
    "    db = db / m\n",
    "\n",
    "    for j in range(n):\n",
    "        dw[j] = dw[j] + (lambda_/m) * w[j]\n",
    "\n",
    "    return db,dw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dj_db: 0.6648774569425726\n",
      "Regularized dj_dw:\n",
      " [0.29653214748822276, 0.4911679625918033, 0.21645877535865857]\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(1)\n",
    "X_mp = np.random.rand(5,3)\n",
    "y_mp = np.array([0,1,0,1,0])\n",
    "w_mp = np.random.rand(X_mp.shape[1])\n",
    "b_mp = 0.5\n",
    "lambda_mp = 0.7\n",
    "db_mp,dw_mp = compute_gradient_with_regularization(X_mp,y_mp,w_mp,b_mp,lambda_mp)\n",
    "\n",
    "print(f\"dj_db: {db_mp}\", )\n",
    "print(f\"Regularized dj_dw:\\n {dw_mp.tolist()}\", )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute gradient for logistic regression\n",
    "def compute_logistic_gradient_with_regularization(X,y,w,b,lambda_):\n",
    "    m,n = X.shape\n",
    "    dw = np.zeros(n)\n",
    "    db = 0\n",
    "    for i in range(m):\n",
    "        fwb_i = np.dot(X[i],w) + b \n",
    "        err_i = sigmoid(fwb_i) - y[i]\n",
    "        for j in range (n):\n",
    "            dw[j] = dw[j] + (err_i * X[i][j])\n",
    "        db = db + err_i\n",
    "    db = db/m\n",
    "    dw = dw/m\n",
    "\n",
    "\n",
    "    for j in range (n):\n",
    "        dw[j] = dw[j] + (lambda_/m) * w[j]   \n",
    "\n",
    "    return db,dw\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dj_db: 0.341798994972791\n",
      "Regularized dj_dw:\n",
      " [0.17380012933994293, 0.32007507881566943, 0.10776313396851499]\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(1)\n",
    "X_tmp = np.random.rand(5,3)\n",
    "y_tmp = np.array([0,1,0,1,0])\n",
    "w_tmp = np.random.rand(X_tmp.shape[1])\n",
    "b_tmp = 0.5\n",
    "lambda_tmp = 0.7\n",
    "dj_db_tmp, dj_dw_tmp =  compute_logistic_gradient_with_regularization(X_tmp, y_tmp, w_tmp, b_tmp, lambda_tmp)\n",
    "\n",
    "print(f\"dj_db: {dj_db_tmp}\", )\n",
    "print(f\"Regularized dj_dw:\\n {dj_dw_tmp.tolist()}\", )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mp1_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
